{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shap_flow_util import read_csv_between\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v2'\n",
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "periods = [('2018-01-01', '2021-09-30'),\n",
    "            ('2021-10-01', '2023-12-31'),\n",
    "            ('2018-01-01', '2023-12-31')]\n",
    "\n",
    "targets = ['price', 'export']\n",
    "for target in targets:\n",
    "    for start_date, end_date in periods:\n",
    "        model_name = 'xgb_{}_start_{}_end_{}'.format(target, start_date, end_date, version)\n",
    "        X = read_csv_between('./data/{}/X_full.csv'.format(version, target), start_date, end_date)\n",
    "        X['isworkingday'] = X['isworkingday']*1.0 # fixes problem with boolean data types (by making boolean type a float)\n",
    "        y = read_csv_between('./data/{}/y_{}_full.csv'.format(version, target), start_date, end_date)\n",
    "\n",
    "        # split data into test and train set\n",
    "        # 4-day sliding window split to prevent memorization of target\n",
    "        block_size = '4d'\n",
    "        masker = [pd.Series(g.index) for n, g in X.groupby(pd.Grouper(freq=block_size))]\n",
    "        train_mask, test_mask = train_test_split(masker, test_size = 0.2, random_state=7)\n",
    "\n",
    "        X_train = X.loc[pd.concat(train_mask)]\n",
    "        y_train = y.loc[pd.concat(train_mask)]\n",
    "        X_test = X.loc[pd.concat(test_mask)]\n",
    "        y_test = y.loc[pd.concat(test_mask)]\n",
    "\n",
    "        xgb_train = xgb.DMatrix(X_train, label=y_train)\n",
    "        xgb_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "        # save test data in order to calculate shap values later\n",
    "        X_test.to_csv('./data/{}/X_test_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "        y_test.to_csv('./data/{}/y_test_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "        # save train data\n",
    "        X_train.to_csv('./data/{}/X_train_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "        y_train.to_csv('./data/{}/y_train_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "\n",
    "\n",
    "        # conventional CV on 4 day window\n",
    "        from scipy.stats import randint, uniform\n",
    "        param_dist = {\n",
    "            'max_depth': randint(3, 12),\n",
    "            'learning_rate': uniform(0.01, 0.3),\n",
    "            'subsample': uniform(0.5, 0.5),\n",
    "            'min_child_weight': randint(1, 31),\n",
    "            'reg_lambda': uniform(0, 1),\n",
    "            'reg_alpha': uniform(0, 1)\n",
    "        }\n",
    "\n",
    "        xgb_model = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                                    n_estimators=1200,\n",
    "                                    verbosity=1, \n",
    "                                    n_jobs=40, \n",
    "                                    base_score = y_train.iloc[:, 0].mean(),\n",
    "                                    random_state=42)\n",
    "        random_search = RandomizedSearchCV(\n",
    "                                    estimator=xgb_model, \n",
    "                                    param_distributions=param_dist, \n",
    "                                    cv=5, \n",
    "                                    n_iter=60,\n",
    "                                    n_jobs=1,\n",
    "                                    refit='neg_root_mean_squared_error', \n",
    "                                    random_state=42,\n",
    "                                    pre_dispatch='2*n_jobs', \n",
    "                                    verbose=3,\n",
    "                                    scoring=['neg_root_mean_squared_error', 'neg_mean_absolute_error', 'r2'])\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = random_search.best_estimator_\n",
    "        best_parameters = random_search.best_params_\n",
    "        print(\"Best set of hyperparameters: \", best_parameters)\n",
    "        print(\"Best score: \", random_search.best_score_)\n",
    "        # save model\n",
    "        directory = './models/{}'.format(version)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        best_model.save_model('{}/{}_best.json'.format(directory, model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
